{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to parse .json files\n",
    "## Simple and fast solution\n",
    "\n",
    "So, basically all you need is two libraries, two **built-in** ones.\n",
    "\n",
    "No need to explore and combine what's been written elsewhere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, csv, json\n",
    "\n",
    "os.chdir('/path_to_json_directory')  # exec if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure may be explained as if you took each line (row) from .json file and manually transmitted it to .csv file. As long as .json is designed for that kind of stuff, we may only transmit rows we are interested in.\n",
    "\n",
    "Let's open .json and load it as a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('filename.json', encoding=\"UTF-8\") as json_p:\n",
    "    x = json.load(json_p)\n",
    "# You may struggle parsing unless you define 'encoding'. At least I have such experience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, our variable **x** contains our .json components, and you may well explore what it describes by calling **x**, for example.\n",
    "\n",
    "Next, we select .csv file to which we transmit certain rows from .json file (from our **x** variable). I wasn't asked to parse every row, so I made a list of what had to be parsed.\n",
    "\n",
    "**# If you need a code to parse every row from .json. Let me know, I'll make one using list comprehensions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = csv.writer(open(\"filename.csv\", \"w\"))\n",
    "f.writerow([\"auditorium\", \"auditoriumOid\",\n",
    "            \"beginLesson\", \"building\",\n",
    "            \"date\", \"dateOfNest\",\n",
    "            \"dayOfWeek\", \"dayOfWeekString\",\n",
    "            \"discipline\", \"endLesson\",\n",
    "            \"groupOid\", \"kindOfWork\",\n",
    "            \"lecturer\", \"lecturerOid\",\n",
    "            \"stream\", \"streamOid\",\n",
    "            \"subGroupOid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we open existing .csv in basic directory with prescriptor **'w'** which literally means 'write'. We don't actually pass .csv to a variable as we use *writer* command from *csv* library.\n",
    "\n",
    "Then, by defining certain rows from .json we pass them to the final .csv file with *writerow* command. In other words, **f** here is like a container of our .csv file with defined rows from .json file. These rows will later be transmitted to that .csv file contained in **f**. Hope that's clear enough :>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for row in x:\n",
    "    f.writerow([row[\"auditorium\"],\n",
    "                row[\"auditoriumOid\"],\n",
    "                row[\"beginLesson\"],\n",
    "                row[\"building\"],\n",
    "                row[\"date\"],\n",
    "                row[\"dateOfNest\"],\n",
    "                row[\"dayOfWeek\"],\n",
    "                row[\"dayOfWeekString\"],\n",
    "                row[\"discipline\"],\n",
    "                row[\"endLesson\"],\n",
    "                row[\"groupOid\"],\n",
    "                row[\"kindOfWork\"],\n",
    "                row[\"lecturer\"],\n",
    "                row[\"lecturerOid\"],\n",
    "                row[\"stream\"],\n",
    "                row[\"streamOid\"],\n",
    "                row[\"subGroupOid\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, each row contained in **x** (loaded .json file) will be written to **f** (container of .csv file) if the row name is equal.\n",
    "\n",
    "That will suffice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, here is a quick codechunk to omit blank rows in a .csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('filename_with_blanks.csv') as input, open('new_csv.csv', 'w', newline='') as output:\n",
    "    writer = csv.writer(output)\n",
    "    for row in csv.reader(input):\n",
    "        if any(field.strip() for field in row):\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We open **filename_with_blanks.csv** containing blank rows as **input** and empty **new_csv.csv** file as **output** (**'w'** means 'write').\n",
    "\n",
    "We define **writer** that will pass *NOT* empty rows to **output**, to our new .csv file.\n",
    "\n",
    "Last three strings of code are like a condition: if a **row** in **input** is not empty *->* pass it to **output**. Therefore, only when this condition is satisfied, not empty rows are transmitted from **input** to **output** .csv files.\n",
    "\n",
    "*bye.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
