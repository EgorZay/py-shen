{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Kaggle Titanic Problem Approach via Gradient Boosting a.k.a. GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Beforehand, you may find certain links of great personal interest. I strongly recommend reading sklearn link as to explore variables and their variations:\n",
    "\n",
    "[Gradient Boosting Tuning: .py Example](https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/)\n",
    "\n",
    "[Про Бустинг Вкратце](http://www.machinelearning.ru/wiki/index.php?title=%D0%91%D1%83%D1%81%D1%82%D0%B8%D0%BD%D0%B3)\n",
    "\n",
    "\n",
    "[Sklearn Gradient Boosting Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Okay, let's proceed by loading libraries and reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "full_data = [train, test]\n",
    "PassengerId = test['PassengerId']\n",
    "\n",
    "true = pd.read_csv('predictions/skew.csv')\n",
    "true = true.ix[0:, 1:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To estimate the quality of our model we imply *accuracy score* metrics.\n",
    "\n",
    "Since we are provided with actual results we may easily compare them with the obtained predicitons.\n",
    "\n",
    "Basically, I have sorted real titanic data and picked up values stored in **train.csv**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next code chunk is to prepare our data to future analysis. This technique was created by [Sina](https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for dataset in full_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
    "train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n",
    "\n",
    "for dataset in full_data:\n",
    "    age_avg = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "\n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n",
    "train['CategoricalAge'] = pd.cut(train['Age'], 5)\n",
    "\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\n",
    "                                                 'Don', 'Dr', 'Major', 'Rev', 'Sir',\n",
    "                                                 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "for dataset in full_data:\n",
    "    # Mapping Sex\n",
    "    dataset['Sex'] = dataset['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "\n",
    "    # Mapping titles\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "    # Mapping Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n",
    "\n",
    "    # Mapping Fare\n",
    "    dataset.loc[dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare'] = 2\n",
    "    dataset.loc[dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "    # Mapping Age\n",
    "    dataset.loc[dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[dataset['Age'] > 64, 'Age'] = 4\n",
    "\n",
    "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', \\\n",
    "                 'Parch', 'FamilySize']\n",
    "train = train.drop(drop_elements, axis=1)\n",
    "train = train.drop(['CategoricalAge', 'CategoricalFare'], axis=1)\n",
    "\n",
    "test = test.drop(drop_elements, axis=1)\n",
    "\n",
    "train = train.values\n",
    "test = test.values\n",
    "\n",
    "X = train[0::, 1::]\n",
    "y = train[0::, 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The code above is self-explanatory but you may always check Sina's work to find out about it more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's now look at the basic GB model and its actual *accuracy score* on true values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(random_state=1337, max_feature='auto', warm_start=True)\n",
    "clf.fit(X, y)\n",
    "pred = clf.predict(test)\n",
    "\n",
    "print('Non-biased scoring accuracy is {}'.format(round(accuracy_score(true, pred)), digits=2))\n",
    "\n",
    "# Non-biased scoring accuracy is 0.77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Accuracy looks solid though it's higher on *y-train* set by .3.\n",
    "\n",
    "Next section reveals how to use grid search with multiple parameters. We first of all start to vary **max_feature** with available options by creating a dictionary to which we pass variables of *GradientBoostingClassifier*, or *clf*. Then, to make sure our model is consistent we utilize *KFold* splitter. We accept the classifier parameters with the highest *mean accuracy score* amidst other iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=1337)  # splitting into 5 is basically a default action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "params = {'max_features' : ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "# So we pass our classifier and parameters dictionary to grid. To be completely informed of the process of fitting\n",
    "# We set 'verbose=3' as this prints lots of information. Every model consistency is verified by KFold 'cv' splitter\n",
    "# Mean accuracy score is based on five consequent models with the same parameters. To make this process more\n",
    "# Reliable we define 'shuffle=True' in KFold as it randomises input data\n",
    "\n",
    "clf = GradientBoostingClassifier(random_state=1337, warm_start=True)\n",
    "grid = GridSearchCV(clf, params, scoring='accuracy', verbose=3, cv=cv)  # verbose=[0,1,2,3] is to show fitting process\n",
    "grid.fit(X, y)\n",
    "\n",
    "grid.best_estimator_\n",
    "pred = grid.predict(test)\n",
    "\n",
    "print('Non-biased scoring accuracy is {}'.format(round(accuracy_score(true, pred)), digits=2))\n",
    "\n",
    "# Non-biased scoring accuracy is 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "By tweaking *max_feature* our predictive power surged from 0.77 to 0.78; a massive increase -- I might say.\n",
    "\n",
    "Okay, now let's try to alter *learning_rate* and *n_estimators* as these options are significant and related to training process. All I have heard of is basically rules of thumb as to which values are coherent. For example, *'sqrt'* works fine most of the times. In my case, however, I just tend to create long arrays and spend some time revealing the best possible model. I'll think of creating a time-consumptive 1-leveled functions just for demonstration. But this topic is nevertheless different.\n",
    "\n",
    "In this situation we no longer require KFold data splitter as we actually know the y_test (true values). I just showed it as an example. You might also want to check other splitters in *sklearn.model_selection*, like **ShuffleSplitt** or **train_test_split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "params = {'n_estimators': np.arange(10, 151, 10),\n",
    "         'learning_rate': np.arange(0.1, 0.31, 0.05)}\n",
    "\n",
    "clf = GradientBoostingClassifier(max_features='sqrt', random_state=1337, warm_start=True, max_depth=2)  # max_depth == 2 is the best possible\n",
    "grid = GridSearchCV(clf, params, scoring='accuracy', verbose=3)  # verbose=[0,1,2,3] is to show fitting process\n",
    "grid.fit(X, y)\n",
    "\n",
    "grid.best_estimator_\n",
    "pred = grid.predict(test)\n",
    "\n",
    "print('Non-biased scoring accuracy is {}'.format(round(accuracy_score(true, pred)), ndigits=2))\n",
    "\n",
    "# Non-biased scoring accuracy is 0.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, it's been some time and i'd like to say that **0.79** was the highest that i could climb to. I even run some 1-hour grid algorithms which also gave me **0.79** as a score.\n",
    "Let's check *accuracy score* on train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('train accuracy score is {}'.format(round(grid.score(X, y), digits=2))\n",
    "\n",
    "# train accuracy score is 0.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame({\n",
    "    'PassengerId': PassengerId,\n",
    "    'Survived': pred\n",
    "}); output.to_csv('predictions/GBM_pred.csv', index=False)  # Do not forget to omit indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Okay, 'till next time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
